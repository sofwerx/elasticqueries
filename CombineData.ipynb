{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       _id            _index  _score  \\\n",
      "0  Tue Mar 20 2018 18:16:16 GMT+0000 (UTC)  ifttt-2018-03-20     1.0   \n",
      "1  Tue Mar 20 2018 18:16:17 GMT+0000 (UTC)  ifttt-2018-03-20     1.0   \n",
      "2  Tue Mar 20 2018 18:16:18 GMT+0000 (UTC)  ifttt-2018-03-20     1.0   \n",
      "3  Tue Mar 20 2018 18:16:19 GMT+0000 (UTC)  ifttt-2018-03-20     1.0   \n",
      "4  Tue Mar 20 2018 18:19:51 GMT+0000 (UTC)  ifttt-2018-03-20     1.0   \n",
      "\n",
      "  _source.User _source.action _source.alert _source.device  _source.deviceID  \\\n",
      "0          NaN            NaN           NaN            NaN               NaN   \n",
      "1          NaN            NaN           NaN            NaN               NaN   \n",
      "2          NaN            NaN           NaN            NaN               NaN   \n",
      "3          NaN            NaN           NaN            NaN               NaN   \n",
      "4          NaN            NaN           NaN            NaN               NaN   \n",
      "\n",
      "  _source.location _source.status _source.subject _source.target  \\\n",
      "0              NaN         Locked           Lock1            NaN   \n",
      "1              NaN         Locked           Lock1            NaN   \n",
      "2              NaN         Locked           Lock1            NaN   \n",
      "3              NaN         Locked           Lock1            NaN   \n",
      "4              NaN       Unlocked           Lock1            NaN   \n",
      "\n",
      "   _source.target-deviceID _source.time         _source.timestamp  \\\n",
      "0                      NaN          NaN  2018-03-20T18:16:16.658Z   \n",
      "1                      NaN          NaN  2018-03-20T18:16:17.696Z   \n",
      "2                      NaN          NaN  2018-03-20T18:16:18.707Z   \n",
      "3                      NaN          NaN  2018-03-20T18:16:19.732Z   \n",
      "4                      NaN          NaN  2018-03-20T18:19:51.759Z   \n",
      "\n",
      "  _source.user    _type                DateTime desired_output  \n",
      "0          NaN  webhook 2018-03-20 14:16:16.658                 \n",
      "1          NaN  webhook 2018-03-20 14:16:17.696                 \n",
      "2          NaN  webhook 2018-03-20 14:16:18.707                 \n",
      "3          NaN  webhook 2018-03-20 14:16:19.732                 \n",
      "4          NaN  webhook 2018-03-20 14:19:51.759                 \n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "########################## Data Prepartion - Event Generation######################\n",
    "###################################################################################\n",
    "\n",
    "# Notes\n",
    "# Each Data Source will be dowloaded independently\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Variables\n",
    "   \n",
    "# Datafile Name\n",
    "datafile = \"transaction_data.csv\"\n",
    "datetimename = 'DateTime'\n",
    "annoyingColumns = ['_id', datetimename,'_index']\n",
    "person = True\n",
    "\n",
    "\n",
    "\n",
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from summarizeDataFrame import summarizeDataset\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "baseline = pd.read_csv(\"time_taken.csv\")\n",
    "\n",
    "baseline['date']='2018-03-30'\n",
    "\n",
    "# baseline['Front Motion Sent'] = pd.to_datetime(baseline['Front Motion Sent']).dt.time\n",
    "# baseline['Motion Sensor 2 Received'] = pd.to_datetime(baseline['Motion Sensor 2 Received']).dt.time\n",
    "#print(baseline.dtypes)\n",
    "baseline['starttime'] =  pd.to_datetime(baseline['date'] + ' ' + baseline['Front Motion Sent'])\n",
    "baseline['endtime'] =  pd.to_datetime(baseline['date'] + ' ' + baseline['Motion Sensor 2 Received'])\n",
    "\n",
    "baseline = baseline.dropna()\n",
    "# starttime = baseline.loc[:,'Front Motion Sent'].values\n",
    "# endtime = baseline.loc[:,'Motion Sensor 2 Received'].values\n",
    "\n",
    "\n",
    "#print(starttime)\n",
    "\n",
    "#print(baseline.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Need to inlcude for Pots\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "# import Data\n",
    "df = pd.read_csv(datafile)\n",
    "\n",
    "# make datetime to datetime format\n",
    "df[datetimename] = pd.to_datetime(df[datetimename])\n",
    "\n",
    "# Initialize Scenario count Variable\n",
    "df['desired_output'] = \"\"\n",
    "\n",
    "\n",
    "# Start and endtime data\n",
    "# array = [\"2018-03-26 18:16:16.658\",\"2018-03-20 18:16:17.696\",\"2018-03-20 18:16:18.707\"]\n",
    "# array2 = [\"2018-04-02 18:16:19.732\",\"2018-03-20 18:16:19.732\",\"2018-03-20 18:16:19.732\"]\n",
    "array = baseline['starttime'].values\n",
    "array2 = baseline['endtime'].values\n",
    "\n",
    "\n",
    "# Create unique identifier for scenario aggregation\n",
    "count = 1\n",
    "\n",
    "for i,x in zip(array,array2):\n",
    "        \n",
    "    df['desired_output'] = np.where(np.logical_and(df[datetimename] >= pd.to_datetime(i) , df[datetimename] <= pd.to_datetime(x)), count , df['desired_output'])   \n",
    "\n",
    "    count = count + 1\n",
    "    \n",
    "\n",
    "    \n",
    "#print(df)    \n",
    "    \n",
    "# Filter Data for no unique and high unique\n",
    "if person == True:\n",
    "    \n",
    "    df2 = df.loc[:,df.apply(pd.Series.nunique) != int(len(df.index))]\n",
    "    \n",
    "else:\n",
    "    \n",
    "    do = df.loc[:,'desired_output']\n",
    "    df1 = df.loc[:,df.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "    df2 = df1.loc[:,df1.apply(pd.Series.nunique) != int(len(df1.index))]\n",
    "    \n",
    "    if 'desired_output' not in df2.columns:\n",
    "        \n",
    "        \n",
    "        \n",
    "        df2 = pd.concat([do,df2], axis=1)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Remove Unessary Columns\n",
    "if all([item in df2.columns for item in annoyingColumns]):\n",
    "    \n",
    "    df3 = df2.drop(annoyingColumns, axis=1)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    df3 = df2\n",
    "\n",
    "\n",
    "\n",
    "# Get names of column aggregation    \n",
    "names = list(df3)\n",
    "if 'desired_output' in names:\n",
    "    \n",
    "    names.remove('desired_output')\n",
    "\n",
    "else:\n",
    "    \n",
    "    print(\"Scenario Not in Dataset\")\n",
    "    print(list(df2))\n",
    "    sys.exit()\n",
    "    \n",
    "\n",
    "        \n",
    "#print(df3)      \n",
    "\n",
    "# Create Dummy Variable for Dataset\n",
    "df5 = pd.get_dummies(df3,columns=names)\n",
    "df5.index = df[datetimename]\n",
    "\n",
    "#df6=df5.resample(\"5T\").count()\n",
    "\n",
    "df6 =df5.groupby(['desired_output'])[list(df5)].count()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df2  = df1.groupby(['_source.device']).agg({'_source.action': [ min , max ,'first', 'nunique','count']})\n",
    "\n",
    "\n",
    "\n",
    "#summarizeDataset(df3)\n",
    "\n",
    "\n",
    "#print(df1.head())\n",
    "\n",
    "#print(list(df4))\n",
    "#print(type(names1))\n",
    "#print(df5.head())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
